{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6228bc1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6228bc1c",
        "outputId": "fb845e61-cc5e-4839-9774-9f56dc526421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (3.11.12)\n",
            "Requirement already satisfied: fsspec in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (6.1.1)\n",
            "Requirement already satisfied: pyparsing in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from requests->torch_geometric) (2024.12.14)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bdWYrgjeZerj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdWYrgjeZerj",
        "outputId": "a1df1bdc-ad74-410f-9378-058c587a5db8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"from google.colab import drive\\ndrive.mount('/content/drive')\""
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"from google.colab import drive\n",
        "drive.mount('/content/drive')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "817b1078",
      "metadata": {
        "id": "817b1078"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "# PyG\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "# Vostri moduli\n",
        "from src.loadData    import (GraphDataset, TestDataset)\n",
        "from src.models      import (GNN, GCODWrapper)\n",
        "from src.transforms import EdgeDropout, NodeDropout, Compose\n",
        "from src.losses import (\n",
        "    GCODLoss,\n",
        "    NoisyCrossEntropyLoss,\n",
        "    GeneralizedCELoss,\n",
        "    SymmetricCELoss,\n",
        "    estimate_transition_matrix,\n",
        "    ForwardCorrectionLoss,\n",
        "    BootstrappingLoss\n",
        ")\n",
        "from src.divide_mix_def import DivideMixTrainer\n",
        "from src.utils import set_seed\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0a9c70d7",
      "metadata": {
        "id": "0a9c70d7"
      },
      "outputs": [],
      "source": [
        "def add_zeros(data):\n",
        "    if not hasattr(data, 'x') or data.x is None:\n",
        "        data.x = torch.zeros(data.num_nodes, dtype=torch.long)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3622cfa1",
      "metadata": {
        "id": "3622cfa1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'def train(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch):\\n    \\n    model = model.to(device)\\n    model.train()\\n    total_loss = 0\\n    correct = 0\\n    total = 0\\n    \\n    for data in tqdm(data_loader, desc=\"Iterating training graphs\", unit=\"batch\"):\\n        data = data.to(device)\\n        optimizer.zero_grad()\\n        output = model(data)\\n        loss = criterion(output, data.y)\\n        loss.backward()\\n        optimizer.step()\\n        total_loss += loss.item()\\n        pred = output.argmax(dim=1)\\n        correct += (pred == data.y).sum().item()\\n        total += data.y.size(0)\\n\\n    # Save checkpoints if required\\n    if save_checkpoints:\\n        checkpoint_file = f\"{checkpoint_path}_epoch_{current_epoch + 1}.pth\"\\n        torch.save(model.state_dict(), checkpoint_file)\\n        print(f\"Checkpoint saved at {checkpoint_file}\")\\n\\n    print(f\"Train loss/acc: {total_loss / len(data_loader):.4f}/{correct / total:.4f}\")\\n    return total_loss / len(data_loader),  correct / total'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"def train(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch):\n",
        "    \n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for data in tqdm(data_loader, desc=\"Iterating training graphs\", unit=\"batch\"):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "        total += data.y.size(0)\n",
        "\n",
        "    # Save checkpoints if required\n",
        "    if save_checkpoints:\n",
        "        checkpoint_file = f\"{checkpoint_path}_epoch_{current_epoch + 1}.pth\"\n",
        "        torch.save(model.state_dict(), checkpoint_file)\n",
        "        print(f\"Checkpoint saved at {checkpoint_file}\")\n",
        "\n",
        "    print(f\"Train loss/acc: {total_loss / len(data_loader):.4f}/{correct / total:.4f}\")\n",
        "    return total_loss / len(data_loader),  correct / total\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b46870e5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate(model, val_loader, device):\n",
        "    \"\"\"Validate model performance on clean validation set.\"\"\"\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "            outputs = model(batch)\n",
        "            preds = outputs.argmax(1)\n",
        "            y_pred.extend(preds.cpu().tolist())\n",
        "            y_true.extend(batch.y.cpu().tolist())\n",
        "    \n",
        "    acc = sum(p == t for p, t in zip(y_pred, y_true)) / len(y_true)\n",
        "    f1 = f1_score(y_true, y_pred, average='macro')\n",
        "    return acc, f1\n",
        "\n",
        "def compute_centroids(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_embeddings = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            batch = batch.to(device)\n",
        "            _ = model(batch)\n",
        "            all_embeddings.append(model.embeddings)\n",
        "            all_labels.append(batch.y)\n",
        "    \n",
        "    embeddings = torch.cat(all_embeddings)\n",
        "    labels = torch.cat(all_labels)\n",
        "\n",
        "    centroids = {}\n",
        "    for label in torch.unique(labels):\n",
        "        label_mask = labels == label\n",
        "        centroids[int(label.item())] = embeddings[label_mask].mean(dim=0)\n",
        "    \n",
        "    return centroids\n",
        "\n",
        "\n",
        "def train(\n",
        "    model,\n",
        "    train_dataset,\n",
        "    val_dataset,\n",
        "    criterion,\n",
        "    main_optimizer,\n",
        "    ub_optimizer, \n",
        "    device,\n",
        "    num_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=32,\n",
        "):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    best_val_f1 = 0\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        y_true_train, y_pred_train = [], []\n",
        "        model = model.to(device)\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            batch = batch.to(device)\n",
        "            labels = batch.y\n",
        "            \n",
        "            torch.autograd.set_detect_anomaly(True)\n",
        "            logits = model(batch)\n",
        "            current_uB = model.uB[batch.idx]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                preds = torch.argmax(logits, dim=1)      # predicted class indices\n",
        "                correct = (preds == labels).sum().item() # number of correct predictions\n",
        "                total = labels.size(0)                   # batch size\n",
        "                train_acc = correct / total              # batch accuracy\n",
        "\n",
        "            \n",
        "            loss, l1, l2, l3 = criterion(logits=logits, \n",
        "                                         uB=current_uB,\n",
        "                                         labels=labels, \n",
        "                                         train_acc=train_acc)\n",
        "\n",
        "\n",
        "            \n",
        "\n",
        "            main_optimizer.zero_grad()\n",
        "            (l1+l3).backward(retain_graph=True)\n",
        "            main_optimizer.step()\n",
        "\n",
        "            # --- uB update pass ---\n",
        "            with torch.no_grad():\n",
        "                logits = model.gnn(batch)  # Recompute with updated θ\n",
        "            \n",
        "            current_uB = model.uB[batch.idx].requires_grad_()\n",
        "            probs = F.softmax(logits, dim=1)\n",
        "            num_classes = 6\n",
        "            yB = F.one_hot(labels, num_classes).float()\n",
        "            adjusted_probs = probs + torch.diag(current_uB) @ yB\n",
        "            L2 = torch.norm(adjusted_probs - yB, p=2)**2 / num_classes\n",
        "            \n",
        "            ub_optimizer.zero_grad()\n",
        "            L2.backward()\n",
        "            ub_optimizer.step()\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                model.uB.clamp_(0, 1)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = logits.argmax(dim=1)\n",
        "\n",
        "            y_pred_train.extend(preds.cpu().tolist())\n",
        "            y_true_train.extend(labels.cpu().tolist())\n",
        "\n",
        "        # Compute training metrics\n",
        "        train_acc = sum(p == t for p, t in zip(y_pred_train, y_true_train)) / len(y_true_train)\n",
        "        train_f1 = f1_score(y_true_train, y_pred_train, average='macro')\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        val_acc, val_f1 = validate(model, val_loader, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: \"\n",
        "              f\"Train Loss={avg_train_loss:.4f}, \"\n",
        "              f\"Train Acc={train_acc:.4f}, \"\n",
        "              f\"Train F1={train_f1:.4f}, \"\n",
        "              f\"Val Acc={val_acc:.4f}, \"\n",
        "              f\"Val F1={val_f1:.4f} (Best={best_val_f1:.4f})\")\n",
        "\n",
        "        # Early stopping based on F1\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_model_state = deepcopy(model.state_dict())\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "    # Restore best model\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f0a68739",
      "metadata": {},
      "outputs": [],
      "source": [
        "def warmup_train(\n",
        "    model,\n",
        "    train_dataset,\n",
        "    val_dataset,\n",
        "    device,\n",
        "    num_epochs=20,\n",
        "    patience=5,\n",
        "    batch_size=32,\n",
        "    lr=1e-3\n",
        "):\n",
        "    model = model.to(device)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses, val_losses = [], []\n",
        "    train_f1s, val_f1s = [], []\n",
        "\n",
        "    best_val_f1 = 0\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        y_true_train, y_pred_train = [], []\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"[Warmup] Epoch {epoch+1}/{num_epochs}\"):\n",
        "            batch = batch.to(device)\n",
        "            labels = batch.y\n",
        "\n",
        "            logits = model.gnn(batch)  # Only run GNN, no wrapper logic needed\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            y_true_train.extend(labels.cpu().tolist())\n",
        "            y_pred_train.extend(preds.cpu().tolist())\n",
        "\n",
        "        # Training metrics\n",
        "        train_acc = sum(p == t for p, t in zip(y_pred_train, y_true_train)) / len(y_true_train)\n",
        "        train_f1 = f1_score(y_true_train, y_pred_train, average='macro')\n",
        "        avg_train_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "        train_losses.append(avg_train_loss)\n",
        "        train_f1s.append(train_f1)\n",
        "\n",
        "        # Validation\n",
        "        val_acc, val_f1 = validate(model, val_loader, device)\n",
        "        val_f1s.append(val_f1)\n",
        "\n",
        "        print(f\"[Warmup] Epoch {epoch+1}: \"\n",
        "              f\"Train Loss={avg_train_loss:.4f}, Train Acc={train_acc:.4f}, Train F1={train_f1:.4f}, \"\n",
        "              f\"Val Acc={val_acc:.4f}, Val F1={val_f1:.4f} (Best={best_val_f1:.4f})\")\n",
        "\n",
        "        # Early stopping\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_model_state = deepcopy(model.state_dict())\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"[Warmup] Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "    if best_model_state:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6139b912",
      "metadata": {
        "id": "6139b912"
      },
      "outputs": [],
      "source": [
        "def evaluate(data_loader, model, device, calculate_accuracy=False):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictions = []\n",
        "    total_loss = 0\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(data_loader, desc=\"Iterating eval graphs\", unit=\"batch\"):\n",
        "            data = data.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)\n",
        "\n",
        "            if calculate_accuracy:\n",
        "                correct += (pred == data.y).sum().item()\n",
        "                total += data.y.size(0)\n",
        "                total_loss += criterion(output, data.y).item()\n",
        "            else:\n",
        "                predictions.extend(pred.cpu().numpy())\n",
        "\n",
        "    \n",
        "    if calculate_accuracy:\n",
        "        accuracy = correct / total\n",
        "        return  total_loss / len(data_loader),accuracy\n",
        "        print(f\"Test loss/acc {total_loss / len(data_loader):.4f} / {correct / total:.4f}\")\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fbdbd871",
      "metadata": {
        "id": "fbdbd871"
      },
      "outputs": [],
      "source": [
        "def save_predictions(predictions, test_path):\n",
        "    script_dir = os.getcwd()\n",
        "    submission_folder = os.path.join(script_dir, \"submission\")\n",
        "    test_dir_name = os.path.basename(os.path.dirname(test_path))\n",
        "\n",
        "    os.makedirs(submission_folder, exist_ok=True)\n",
        "\n",
        "    output_csv_path = os.path.join(submission_folder, f\"testset_{test_dir_name}.csv\")\n",
        "\n",
        "    test_graph_ids = list(range(len(predictions)))\n",
        "    output_df = pd.DataFrame({\n",
        "        \"id\": test_graph_ids,\n",
        "        \"pred\": predictions\n",
        "    })\n",
        "\n",
        "    output_df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Predictions saved to {output_csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fc3d24da",
      "metadata": {
        "id": "fc3d24da"
      },
      "outputs": [],
      "source": [
        "def plot_training_progress(train_losses, train_accuracies, save_plot, output_dir):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label=\"Training Loss\", color='blue')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss per Epoch')\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\", color='green')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training Accuracy per Epoch')\n",
        "\n",
        "    if(save_plot):\n",
        "        # Save plots in the current directory\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, \"training_progress.png\"))\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8cMtQXyuWQol",
      "metadata": {
        "id": "8cMtQXyuWQol"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters\n",
        "device                =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# Modello\n",
        "gnn_type              = 'gin-virtual'   \n",
        "num_layer             = 3\n",
        "emb_dim               = 300\n",
        "drop_ratio            = 0.5\n",
        "\n",
        "pooling               = \"mean\"\n",
        "\n",
        "edge_p  = 0.5   # frazione di bordi da droppare\n",
        "node_p = 0.5\n",
        "\n",
        "epochs                = 100\n",
        "weight_decay          = 1e-4\n",
        "num_classes           = 6\n",
        "batch_size            = 32 \n",
        "warmup_steps          = 10\n",
        "patience              = 12\n",
        "residual              = False\n",
        "model_lr              = 0.001\n",
        "u_lr                  = 1\n",
        "\n",
        "seed                  = set_seed(42)\n",
        "transforms = Compose([\n",
        "    add_zeros,\n",
        "])\n",
        "\n",
        "# Epoch 49: Train Loss=0.3052, Train Acc=0.9117, Val Acc=0.6953 DATASET C"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41679bf6",
      "metadata": {},
      "source": [
        "# Minimum Effort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "502f55df",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_gnn_model(gnn_type, num_classes, num_layer, emb_dim, drop_ratio, device, residual, pooling):\n",
        "    kwargs = {\n",
        "        'gnn_type': gnn_type.replace(\"-virtual\", \"\"),\n",
        "        'num_class': num_classes,\n",
        "        'num_layer': num_layer,\n",
        "        'emb_dim': emb_dim,\n",
        "        'drop_ratio': drop_ratio,\n",
        "        'virtual_node': \"virtual\" in gnn_type,\n",
        "        'residual': residual,\n",
        "        'graph_pooling': pooling\n",
        "        }\n",
        "\n",
        "    model = GNN(**kwargs).to(device)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b7538579",
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_dataset(dataset: GraphDataset, val_ratio=0.1, seed=42):\n",
        "    labels = torch.tensor([data.y.item() for data in dataset])\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, val_idx = train_test_split(\n",
        "        indices,\n",
        "        test_size=val_ratio,\n",
        "        stratify=labels,\n",
        "        random_state=seed\n",
        "    )\n",
        "\n",
        "    train_subset = []\n",
        "    val_subset = []\n",
        "\n",
        "    for new_idx, original_idx in enumerate(train_idx):\n",
        "        data = dataset[original_idx]\n",
        "        data.idx = new_idx  # Normalize index\n",
        "        train_subset.append(data)\n",
        "\n",
        "    for new_idx, original_idx in enumerate(val_idx):\n",
        "        data = dataset[original_idx]\n",
        "        data.idx = new_idx  # Normalize index\n",
        "        val_subset.append(data)\n",
        "\n",
        "    return train_subset, val_subset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4696ca96",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating dataset\n",
            "Splitting dataset\n",
            "Warmup Step (10 Epochs)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 1/10: 100%|██████████| 282/282 [00:08<00:00, 32.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 1: Train Loss=1.6957, Train Acc=0.3125, Train F1=0.1762, Val Acc=0.3262, Val F1=0.1501 (Best=0.0000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 2/10: 100%|██████████| 282/282 [00:08<00:00, 33.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 2: Train Loss=1.5927, Train Acc=0.3709, Train F1=0.2080, Val Acc=0.3497, Val F1=0.2006 (Best=0.1501)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 3/10: 100%|██████████| 282/282 [00:08<00:00, 33.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 3: Train Loss=1.5695, Train Acc=0.3801, Train F1=0.2182, Val Acc=0.3515, Val F1=0.2009 (Best=0.2006)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 4/10: 100%|██████████| 282/282 [00:08<00:00, 33.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 4: Train Loss=1.5383, Train Acc=0.3941, Train F1=0.2461, Val Acc=0.3803, Val F1=0.2733 (Best=0.2009)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 5/10: 100%|██████████| 282/282 [00:08<00:00, 32.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 5: Train Loss=1.5088, Train Acc=0.4137, Train F1=0.2706, Val Acc=0.3586, Val F1=0.2509 (Best=0.2733)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 6/10: 100%|██████████| 282/282 [00:08<00:00, 33.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 6: Train Loss=1.4860, Train Acc=0.4285, Train F1=0.2859, Val Acc=0.4317, Val F1=0.2912 (Best=0.2733)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 7/10: 100%|██████████| 282/282 [00:08<00:00, 33.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 7: Train Loss=1.4616, Train Acc=0.4430, Train F1=0.3123, Val Acc=0.3449, Val F1=0.2462 (Best=0.2912)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 8/10: 100%|██████████| 282/282 [00:08<00:00, 33.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 8: Train Loss=1.4418, Train Acc=0.4563, Train F1=0.3354, Val Acc=0.4229, Val F1=0.3232 (Best=0.2912)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 9/10: 100%|██████████| 282/282 [00:08<00:00, 32.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 9: Train Loss=1.4230, Train Acc=0.4686, Train F1=0.3592, Val Acc=0.4601, Val F1=0.3356 (Best=0.3232)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 10/10: 100%|██████████| 282/282 [00:08<00:00, 32.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Warmup] Epoch 10: Train Loss=1.3996, Train Acc=0.4863, Train F1=0.3787, Val Acc=0.4960, Val F1=0.3687 (Best=0.3356)\n",
            "Train (100 Epochs)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/100: 100%|██████████| 282/282 [00:18<00:00, 15.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss=5.0522, Train Acc=0.5027, Train F1=0.4041, Val Acc=0.4801, Val F1=0.3467 (Best=0.0000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/100: 100%|██████████| 282/282 [00:19<00:00, 14.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Train Loss=3.5665, Train Acc=0.5084, Train F1=0.4159, Val Acc=0.5191, Val F1=0.4243 (Best=0.3467)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/100: 100%|██████████| 282/282 [00:18<00:00, 14.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Train Loss=3.6986, Train Acc=0.5253, Train F1=0.4363, Val Acc=0.4898, Val F1=0.3508 (Best=0.4243)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/100: 100%|██████████| 282/282 [00:19<00:00, 14.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: Train Loss=3.7005, Train Acc=0.5265, Train F1=0.4438, Val Acc=0.5230, Val F1=0.4282 (Best=0.4243)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/100: 100%|██████████| 282/282 [00:18<00:00, 15.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: Train Loss=3.6637, Train Acc=0.5489, Train F1=0.4668, Val Acc=0.4756, Val F1=0.3259 (Best=0.4282)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/100: 100%|██████████| 282/282 [00:18<00:00, 15.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: Train Loss=3.6351, Train Acc=0.5481, Train F1=0.4701, Val Acc=0.5656, Val F1=0.4661 (Best=0.4282)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/100: 100%|██████████| 282/282 [00:18<00:00, 15.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: Train Loss=3.6240, Train Acc=0.5512, Train F1=0.4743, Val Acc=0.5811, Val F1=0.4875 (Best=0.4661)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/100: 100%|██████████| 282/282 [00:18<00:00, 15.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: Train Loss=3.5618, Train Acc=0.5617, Train F1=0.4911, Val Acc=0.5355, Val F1=0.4120 (Best=0.4875)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/100: 100%|██████████| 282/282 [00:18<00:00, 15.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: Train Loss=3.5644, Train Acc=0.5756, Train F1=0.5063, Val Acc=0.5811, Val F1=0.4850 (Best=0.4875)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/100: 100%|██████████| 282/282 [00:18<00:00, 15.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: Train Loss=3.4862, Train Acc=0.5833, Train F1=0.5183, Val Acc=0.5381, Val F1=0.4894 (Best=0.4875)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/100: 100%|██████████| 282/282 [00:18<00:00, 15.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss=3.4986, Train Acc=0.5840, Train F1=0.5208, Val Acc=0.6020, Val F1=0.5342 (Best=0.4894)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/100: 100%|██████████| 282/282 [00:18<00:00, 15.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss=3.4230, Train Acc=0.5971, Train F1=0.5342, Val Acc=0.5820, Val F1=0.5048 (Best=0.5342)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/100: 100%|██████████| 282/282 [00:18<00:00, 15.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Train Loss=3.3944, Train Acc=0.6024, Train F1=0.5396, Val Acc=0.5918, Val F1=0.5086 (Best=0.5342)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/100: 100%|██████████| 282/282 [00:18<00:00, 15.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Train Loss=3.3998, Train Acc=0.6093, Train F1=0.5499, Val Acc=0.6144, Val F1=0.5564 (Best=0.5342)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/100: 100%|██████████| 282/282 [00:18<00:00, 15.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: Train Loss=3.3243, Train Acc=0.6212, Train F1=0.5658, Val Acc=0.6179, Val F1=0.5440 (Best=0.5564)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/100: 100%|██████████| 282/282 [00:18<00:00, 15.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Train Loss=3.2967, Train Acc=0.6168, Train F1=0.5611, Val Acc=0.6268, Val F1=0.5588 (Best=0.5564)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/100: 100%|██████████| 282/282 [00:18<00:00, 15.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Train Loss=3.2890, Train Acc=0.6281, Train F1=0.5701, Val Acc=0.5505, Val F1=0.4741 (Best=0.5588)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/100: 100%|██████████| 282/282 [00:19<00:00, 14.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: Train Loss=3.2818, Train Acc=0.6377, Train F1=0.5802, Val Acc=0.5887, Val F1=0.5150 (Best=0.5588)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/100: 100%|██████████| 282/282 [00:18<00:00, 15.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: Train Loss=3.2602, Train Acc=0.6372, Train F1=0.5816, Val Acc=0.6498, Val F1=0.5781 (Best=0.5588)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/100: 100%|██████████| 282/282 [00:18<00:00, 14.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: Train Loss=3.1927, Train Acc=0.6489, Train F1=0.5935, Val Acc=0.5590, Val F1=0.4809 (Best=0.5781)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/100: 100%|██████████| 282/282 [00:18<00:00, 14.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21: Train Loss=3.1894, Train Acc=0.6492, Train F1=0.5959, Val Acc=0.6410, Val F1=0.5793 (Best=0.5781)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/100: 100%|██████████| 282/282 [00:18<00:00, 14.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22: Train Loss=3.1576, Train Acc=0.6516, Train F1=0.5970, Val Acc=0.6534, Val F1=0.5796 (Best=0.5793)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/100: 100%|██████████| 282/282 [00:18<00:00, 15.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23: Train Loss=3.1413, Train Acc=0.6510, Train F1=0.5973, Val Acc=0.6396, Val F1=0.5767 (Best=0.5796)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/100: 100%|██████████| 282/282 [00:19<00:00, 14.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24: Train Loss=3.1257, Train Acc=0.6621, Train F1=0.6102, Val Acc=0.6259, Val F1=0.5707 (Best=0.5796)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/100: 100%|██████████| 282/282 [00:19<00:00, 14.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25: Train Loss=3.1084, Train Acc=0.6646, Train F1=0.6130, Val Acc=0.6263, Val F1=0.5785 (Best=0.5796)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/100: 100%|██████████| 282/282 [00:18<00:00, 15.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26: Train Loss=3.0828, Train Acc=0.6697, Train F1=0.6164, Val Acc=0.6769, Val F1=0.6192 (Best=0.5796)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/100: 100%|██████████| 282/282 [00:18<00:00, 14.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27: Train Loss=3.0758, Train Acc=0.6727, Train F1=0.6215, Val Acc=0.5395, Val F1=0.5103 (Best=0.6192)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/100: 100%|██████████| 282/282 [00:18<00:00, 15.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28: Train Loss=3.0310, Train Acc=0.6762, Train F1=0.6248, Val Acc=0.6662, Val F1=0.6052 (Best=0.6192)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/100: 100%|██████████| 282/282 [00:18<00:00, 15.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29: Train Loss=3.0540, Train Acc=0.6811, Train F1=0.6286, Val Acc=0.6689, Val F1=0.6051 (Best=0.6192)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/100: 100%|██████████| 282/282 [00:18<00:00, 14.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30: Train Loss=3.0390, Train Acc=0.6795, Train F1=0.6286, Val Acc=0.6636, Val F1=0.6004 (Best=0.6192)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/100: 100%|██████████| 282/282 [00:18<00:00, 15.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31: Train Loss=2.9992, Train Acc=0.6853, Train F1=0.6344, Val Acc=0.6738, Val F1=0.6059 (Best=0.6192)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/100: 100%|██████████| 282/282 [00:18<00:00, 14.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32: Train Loss=3.0389, Train Acc=0.6812, Train F1=0.6298, Val Acc=0.6742, Val F1=0.6204 (Best=0.6192)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/100: 100%|██████████| 282/282 [00:18<00:00, 15.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33: Train Loss=2.9755, Train Acc=0.6885, Train F1=0.6352, Val Acc=0.6800, Val F1=0.6215 (Best=0.6204)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/100: 100%|██████████| 282/282 [00:18<00:00, 15.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34: Train Loss=2.9839, Train Acc=0.6869, Train F1=0.6365, Val Acc=0.6476, Val F1=0.5837 (Best=0.6215)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/100: 100%|██████████| 282/282 [00:18<00:00, 15.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35: Train Loss=2.9394, Train Acc=0.6944, Train F1=0.6414, Val Acc=0.6853, Val F1=0.6247 (Best=0.6215)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/100: 100%|██████████| 282/282 [00:18<00:00, 14.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36: Train Loss=2.9547, Train Acc=0.6965, Train F1=0.6436, Val Acc=0.6330, Val F1=0.5852 (Best=0.6247)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/100: 100%|██████████| 282/282 [00:18<00:00, 15.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37: Train Loss=2.9410, Train Acc=0.6987, Train F1=0.6475, Val Acc=0.6937, Val F1=0.6357 (Best=0.6247)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/100: 100%|██████████| 282/282 [00:18<00:00, 15.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38: Train Loss=2.8962, Train Acc=0.7055, Train F1=0.6560, Val Acc=0.6769, Val F1=0.6168 (Best=0.6357)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/100: 100%|██████████| 282/282 [00:19<00:00, 14.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39: Train Loss=2.9125, Train Acc=0.7014, Train F1=0.6514, Val Acc=0.6534, Val F1=0.5996 (Best=0.6357)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/100: 100%|██████████| 282/282 [00:18<00:00, 15.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40: Train Loss=2.8902, Train Acc=0.7031, Train F1=0.6511, Val Acc=0.6835, Val F1=0.6289 (Best=0.6357)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/100: 100%|██████████| 282/282 [00:19<00:00, 14.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41: Train Loss=2.8926, Train Acc=0.7070, Train F1=0.6549, Val Acc=0.6560, Val F1=0.5924 (Best=0.6357)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/100: 100%|██████████| 282/282 [00:18<00:00, 15.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42: Train Loss=2.8750, Train Acc=0.7056, Train F1=0.6554, Val Acc=0.6764, Val F1=0.6215 (Best=0.6357)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/100: 100%|██████████| 282/282 [00:18<00:00, 15.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43: Train Loss=2.8698, Train Acc=0.7072, Train F1=0.6576, Val Acc=0.6724, Val F1=0.6166 (Best=0.6357)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44/100: 100%|██████████| 282/282 [00:18<00:00, 15.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44: Train Loss=2.8548, Train Acc=0.7056, Train F1=0.6563, Val Acc=0.6862, Val F1=0.6326 (Best=0.6357)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45/100: 100%|██████████| 282/282 [00:18<00:00, 15.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45: Train Loss=2.8462, Train Acc=0.7102, Train F1=0.6607, Val Acc=0.6871, Val F1=0.6274 (Best=0.6357)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46/100: 100%|██████████| 282/282 [00:18<00:00, 15.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46: Train Loss=2.8013, Train Acc=0.7168, Train F1=0.6665, Val Acc=0.7070, Val F1=0.6553 (Best=0.6357)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47/100: 100%|██████████| 282/282 [00:18<00:00, 15.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47: Train Loss=2.8463, Train Acc=0.7131, Train F1=0.6625, Val Acc=0.6871, Val F1=0.6347 (Best=0.6553)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48/100: 100%|██████████| 282/282 [00:18<00:00, 15.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48: Train Loss=2.8070, Train Acc=0.7190, Train F1=0.6688, Val Acc=0.6330, Val F1=0.5839 (Best=0.6553)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49/100: 100%|██████████| 282/282 [00:18<00:00, 15.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49: Train Loss=2.7945, Train Acc=0.7178, Train F1=0.6676, Val Acc=0.6977, Val F1=0.6365 (Best=0.6553)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50/100: 100%|██████████| 282/282 [00:18<00:00, 15.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50: Train Loss=2.7683, Train Acc=0.7234, Train F1=0.6699, Val Acc=0.6751, Val F1=0.6290 (Best=0.6553)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 51/100: 100%|██████████| 282/282 [00:18<00:00, 15.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51: Train Loss=2.8073, Train Acc=0.7151, Train F1=0.6661, Val Acc=0.6246, Val F1=0.5752 (Best=0.6553)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 52/100: 100%|██████████| 282/282 [00:18<00:00, 15.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52: Train Loss=2.7494, Train Acc=0.7250, Train F1=0.6733, Val Acc=0.7026, Val F1=0.6425 (Best=0.6553)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 53/100: 100%|██████████| 282/282 [00:18<00:00, 15.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53: Train Loss=2.7450, Train Acc=0.7253, Train F1=0.6745, Val Acc=0.6955, Val F1=0.6398 (Best=0.6553)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 54/100: 100%|██████████| 282/282 [00:18<00:00, 15.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54: Train Loss=2.7478, Train Acc=0.7242, Train F1=0.6760, Val Acc=0.7159, Val F1=0.6630 (Best=0.6553)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 55/100: 100%|██████████| 282/282 [00:18<00:00, 15.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55: Train Loss=2.7733, Train Acc=0.7255, Train F1=0.6771, Val Acc=0.6645, Val F1=0.6177 (Best=0.6630)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 56/100: 100%|██████████| 282/282 [00:18<00:00, 15.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56: Train Loss=2.7164, Train Acc=0.7250, Train F1=0.6756, Val Acc=0.6449, Val F1=0.6018 (Best=0.6630)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 57/100: 100%|██████████| 282/282 [00:18<00:00, 15.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57: Train Loss=2.7242, Train Acc=0.7299, Train F1=0.6801, Val Acc=0.6866, Val F1=0.6355 (Best=0.6630)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 58/100: 100%|██████████| 282/282 [00:18<00:00, 15.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58: Train Loss=2.7474, Train Acc=0.7270, Train F1=0.6781, Val Acc=0.7017, Val F1=0.6456 (Best=0.6630)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 59/100: 100%|██████████| 282/282 [00:18<00:00, 15.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 59: Train Loss=2.7114, Train Acc=0.7336, Train F1=0.6835, Val Acc=0.6848, Val F1=0.6381 (Best=0.6630)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 60/100: 100%|██████████| 282/282 [00:18<00:00, 15.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 60: Train Loss=2.6975, Train Acc=0.7314, Train F1=0.6840, Val Acc=0.7216, Val F1=0.6696 (Best=0.6630)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 61/100: 100%|██████████| 282/282 [00:18<00:00, 15.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 61: Train Loss=2.6977, Train Acc=0.7303, Train F1=0.6810, Val Acc=0.7052, Val F1=0.6548 (Best=0.6696)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 62/100: 100%|██████████| 282/282 [00:18<00:00, 15.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 62: Train Loss=2.7090, Train Acc=0.7303, Train F1=0.6833, Val Acc=0.6995, Val F1=0.6474 (Best=0.6696)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 63/100: 100%|██████████| 282/282 [00:18<00:00, 15.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 63: Train Loss=2.6762, Train Acc=0.7344, Train F1=0.6832, Val Acc=0.6933, Val F1=0.6487 (Best=0.6696)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 64/100: 100%|██████████| 282/282 [00:18<00:00, 15.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 64: Train Loss=2.6369, Train Acc=0.7401, Train F1=0.6908, Val Acc=0.6751, Val F1=0.6221 (Best=0.6696)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 65/100: 100%|██████████| 282/282 [00:18<00:00, 15.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 65: Train Loss=2.6626, Train Acc=0.7404, Train F1=0.6925, Val Acc=0.7008, Val F1=0.6426 (Best=0.6696)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 66/100: 100%|██████████| 282/282 [00:18<00:00, 15.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 66: Train Loss=2.6439, Train Acc=0.7394, Train F1=0.6931, Val Acc=0.6964, Val F1=0.6473 (Best=0.6696)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 67/100: 100%|██████████| 282/282 [00:18<00:00, 15.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 67: Train Loss=2.6309, Train Acc=0.7420, Train F1=0.6974, Val Acc=0.7203, Val F1=0.6729 (Best=0.6696)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 68/100: 100%|██████████| 282/282 [00:18<00:00, 15.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 68: Train Loss=2.6087, Train Acc=0.7419, Train F1=0.6957, Val Acc=0.7048, Val F1=0.6589 (Best=0.6729)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 69/100: 100%|██████████| 282/282 [00:18<00:00, 15.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 69: Train Loss=2.6091, Train Acc=0.7446, Train F1=0.6980, Val Acc=0.6928, Val F1=0.6471 (Best=0.6729)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 70/100: 100%|██████████| 282/282 [00:18<00:00, 15.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 70: Train Loss=2.6086, Train Acc=0.7460, Train F1=0.7010, Val Acc=0.6840, Val F1=0.6319 (Best=0.6729)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 71/100: 100%|██████████| 282/282 [00:18<00:00, 15.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 71: Train Loss=2.6149, Train Acc=0.7430, Train F1=0.6965, Val Acc=0.7154, Val F1=0.6626 (Best=0.6729)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 72/100: 100%|██████████| 282/282 [00:18<00:00, 15.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 72: Train Loss=2.6035, Train Acc=0.7469, Train F1=0.7020, Val Acc=0.7052, Val F1=0.6521 (Best=0.6729)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 73/100: 100%|██████████| 282/282 [00:18<00:00, 15.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 73: Train Loss=2.5751, Train Acc=0.7469, Train F1=0.7017, Val Acc=0.6986, Val F1=0.6572 (Best=0.6729)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 74/100: 100%|██████████| 282/282 [00:18<00:00, 15.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 74: Train Loss=2.5924, Train Acc=0.7486, Train F1=0.7046, Val Acc=0.7190, Val F1=0.6695 (Best=0.6729)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 75/100: 100%|██████████| 282/282 [00:18<00:00, 15.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 75: Train Loss=2.5958, Train Acc=0.7428, Train F1=0.6981, Val Acc=0.7008, Val F1=0.6470 (Best=0.6729)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 76/100: 100%|██████████| 282/282 [00:18<00:00, 15.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 76: Train Loss=2.5744, Train Acc=0.7492, Train F1=0.7022, Val Acc=0.5935, Val F1=0.5622 (Best=0.6729)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 77/100: 100%|██████████| 282/282 [00:18<00:00, 15.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 77: Train Loss=2.5423, Train Acc=0.7537, Train F1=0.7102, Val Acc=0.6981, Val F1=0.6547 (Best=0.6729)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 78/100: 100%|██████████| 282/282 [00:18<00:00, 15.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 78: Train Loss=2.5521, Train Acc=0.7503, Train F1=0.7077, Val Acc=0.6950, Val F1=0.6468 (Best=0.6729)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 79/100: 100%|██████████| 282/282 [00:18<00:00, 15.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 79: Train Loss=2.5415, Train Acc=0.7512, Train F1=0.7029, Val Acc=0.7004, Val F1=0.6519 (Best=0.6729)\n",
            "Early stopping triggered!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterating eval graphs: 100%|██████████| 74/74 [00:05<00:00, 14.26batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved to /home/flaviolinux/uni/deep_learning/hackaton/submission/testset_A.csv\n"
          ]
        }
      ],
      "source": [
        "import gc \n",
        "# Modifica loop principale di training\n",
        "train_datasets_path = [\"datasets/C/train.json.gz\"]\n",
        "\n",
        "for ds in train_datasets_path:\n",
        "\n",
        "\n",
        "    print(\"Generating dataset\")\n",
        "    \n",
        "    full_dataset = GraphDataset(ds, transform=transforms).shuffle()\n",
        "    #full_dataset = TestDataset()\n",
        "    print(\"Splitting dataset\")\n",
        "    train_set, val_set = split_dataset(full_dataset, 0.2, seed)\n",
        "    \n",
        "\n",
        "    model_kwargs = {\"gnn_type\": gnn_type, \n",
        "                    \"num_classes\":num_classes, \n",
        "                    \"num_layer\": num_layer, \n",
        "                    \"emb_dim\": emb_dim, \n",
        "                    \"drop_ratio\": drop_ratio, \n",
        "                    \"device\":device, \n",
        "                    \"residual\": residual, \n",
        "                    \"pooling\": pooling,\n",
        "                    }\n",
        "    \n",
        "    model = create_gnn_model(**model_kwargs)\n",
        "\n",
        "    wrapper = GCODWrapper(model, len(train_set))\n",
        "    criterion = GCODLoss(num_classes=num_classes, batch_size=batch_size, device=device)\n",
        "    \n",
        "    theta_optim = torch.optim.Adam(wrapper.gnn.parameters(), lr=model_lr, weight_decay=weight_decay)\n",
        "    u_optim = torch.optim.Adam([wrapper.uB], lr=u_lr, weight_decay=weight_decay)\n",
        "\n",
        "    warmup_criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    print(f\"Warmup Step ({warmup_steps} Epochs)\")\n",
        "    warmup_model = warmup_train(model=wrapper, \n",
        "                       train_dataset=train_set,\n",
        "                       val_dataset=val_set,\n",
        "                       device=device,\n",
        "                       num_epochs=warmup_steps,\n",
        "                       patience = warmup_steps+1,\n",
        "                       batch_size=batch_size \n",
        "                       )\n",
        "\n",
        "    print(f\"Train ({epochs} Epochs)\")\n",
        "    best_model = train(model=warmup_model, \n",
        "                       train_dataset=train_set, \n",
        "                       val_dataset=val_set, \n",
        "                       criterion=criterion, \n",
        "                       main_optimizer=theta_optim,\n",
        "                       ub_optimizer = u_optim,  \n",
        "                       device=device,\n",
        "                       num_epochs=epochs, \n",
        "                       patience=patience, \n",
        "                       batch_size=batch_size)\n",
        "\n",
        "    del val_set, train_set, full_dataset, criterion\n",
        "    gc.collect()\n",
        "\n",
        "    # Test e predizioni\n",
        "    test_loader = DataLoader(GraphDataset(ds.replace(\"train\", \"test\"), transform=transforms), batch_size=32)\n",
        "    #test_loader = DataLoader(TestDataset(), batch_size=batch_size)\n",
        "    predictions = evaluate(test_loader, best_model, device, False)\n",
        "    save_predictions(predictions=predictions, test_path=ds.replace(\"train\", \"test\"))\n",
        "    del test_loader, best_model, predictions\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "machine_learning_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 108.457758,
      "end_time": "2025-05-21T16:25:04.482169",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-05-21T16:23:16.024411",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
