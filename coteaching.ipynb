{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6228bc1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6228bc1c",
        "outputId": "fb845e61-cc5e-4839-9774-9f56dc526421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (3.11.12)\n",
            "Requirement already satisfied: fsspec in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (6.1.1)\n",
            "Requirement already satisfied: pyparsing in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from aiohttp->torch_geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/flaviolinux/machine_learning_env/lib/python3.12/site-packages (from requests->torch_geometric) (2024.12.14)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bdWYrgjeZerj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdWYrgjeZerj",
        "outputId": "a1df1bdc-ad74-410f-9378-058c587a5db8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"from google.colab import drive\\ndrive.mount('/content/drive')\""
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"from google.colab import drive\n",
        "drive.mount('/content/drive')\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "817b1078",
      "metadata": {
        "id": "817b1078"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "# PyG\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# Vostri moduli\n",
        "from src.loadData    import GraphDataset\n",
        "from src.models      import GNN\n",
        "from src.transforms import EdgeDropout, NodeDropout, Compose\n",
        "from src.losses import (\n",
        "    GeneralizedCELoss,\n",
        "    SymmetricCELoss,\n",
        "    estimate_transition_matrix,\n",
        "    ForwardCorrectionLoss,\n",
        "    BootstrappingLoss\n",
        ")\n",
        "from src.pretraining import GraphCLTrainer, add_zeros\n",
        "from src.divide_mix_def import DivideMixTrainer\n",
        "\n",
        "# Fissa seed\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0a9c70d7",
      "metadata": {
        "id": "0a9c70d7"
      },
      "outputs": [],
      "source": [
        "def add_zeros(data):\n",
        "    if not hasattr(data, 'x') or data.x is None:\n",
        "        data.x = torch.zeros(data.num_nodes, dtype=torch.long)\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3622cfa1",
      "metadata": {
        "id": "3622cfa1"
      },
      "outputs": [],
      "source": [
        "def train(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch):\n",
        "    \n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for data in tqdm(data_loader, desc=\"Iterating training graphs\", unit=\"batch\"):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "        total += data.y.size(0)\n",
        "\n",
        "    # Save checkpoints if required\n",
        "    if save_checkpoints:\n",
        "        checkpoint_file = f\"{checkpoint_path}_epoch_{current_epoch + 1}.pth\"\n",
        "        torch.save(model.state_dict(), checkpoint_file)\n",
        "        print(f\"Checkpoint saved at {checkpoint_file}\")\n",
        "\n",
        "    print(f\"Train loss/acc: {total_loss / len(data_loader):.4f}/{correct / total:.4f}\")\n",
        "    return total_loss / len(data_loader),  correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6139b912",
      "metadata": {
        "id": "6139b912"
      },
      "outputs": [],
      "source": [
        "def evaluate(data_loader, model, device, calculate_accuracy=False):\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictions = []\n",
        "    total_loss = 0\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(data_loader, desc=\"Iterating eval graphs\", unit=\"batch\"):\n",
        "            data = data.to(device)\n",
        "            output = model(data)\n",
        "            pred = output.argmax(dim=1)\n",
        "\n",
        "            if calculate_accuracy:\n",
        "                correct += (pred == data.y).sum().item()\n",
        "                total += data.y.size(0)\n",
        "                total_loss += criterion(output, data.y).item()\n",
        "            else:\n",
        "                predictions.extend(pred.cpu().numpy())\n",
        "\n",
        "    \n",
        "    if calculate_accuracy:\n",
        "        accuracy = correct / total\n",
        "        return  total_loss / len(data_loader),accuracy\n",
        "        print(f\"Test loss/acc {total_loss / len(data_loader):.4f} / {correct / total:.4f}\")\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fbdbd871",
      "metadata": {
        "id": "fbdbd871"
      },
      "outputs": [],
      "source": [
        "def save_predictions(predictions, test_path):\n",
        "    script_dir = os.getcwd()\n",
        "    submission_folder = os.path.join(script_dir, \"submission\")\n",
        "    test_dir_name = os.path.basename(os.path.dirname(test_path))\n",
        "\n",
        "    os.makedirs(submission_folder, exist_ok=True)\n",
        "\n",
        "    output_csv_path = os.path.join(submission_folder, f\"testset_{test_dir_name}.csv\")\n",
        "\n",
        "    test_graph_ids = list(range(len(predictions)))\n",
        "    output_df = pd.DataFrame({\n",
        "        \"id\": test_graph_ids,\n",
        "        \"pred\": predictions\n",
        "    })\n",
        "\n",
        "    output_df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Predictions saved to {output_csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fc3d24da",
      "metadata": {
        "id": "fc3d24da"
      },
      "outputs": [],
      "source": [
        "def plot_training_progress(train_losses, train_accuracies, save_plot, output_dir):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label=\"Training Loss\", color='blue')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss per Epoch')\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\", color='green')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training Accuracy per Epoch')\n",
        "\n",
        "    if(save_plot):\n",
        "        # Save plots in the current directory\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(output_dir, \"training_progress.png\"))\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8cMtQXyuWQol",
      "metadata": {
        "id": "8cMtQXyuWQol"
      },
      "outputs": [],
      "source": [
        "# Hyper-parameters\n",
        "device                =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# Modello\n",
        "gnn_type              = 'gin'   \n",
        "num_layer             = 3\n",
        "emb_dim               = 300\n",
        "drop_ratio            = 0.6\n",
        "pooling               = \"attention\"\n",
        "\n",
        "edge_p  = 0.2   # frazione di bordi da droppare\n",
        "node_p  = 0.2\n",
        "# Ottimizzazione / Scheduler\n",
        "lr                    = 0.01\n",
        "epochs                = 100\n",
        "weight_decay          = 5e-4\n",
        "t_max                 = 50\n",
        "eta_min               = 1e-5\n",
        "num_classes           = 6\n",
        "batch_size            = 32 \n",
        "patience              = 12\n",
        "residual              = True\n",
        "transforms = Compose([\n",
        "    add_zeros,\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41679bf6",
      "metadata": {},
      "source": [
        "# Co-Teaching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "502f55df",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_gnn_model(gnn_type, num_classes, num_layer, emb_dim, drop_ratio, pooling, device, residual):\n",
        "    kwargs = {\n",
        "        'gnn_type': gnn_type.replace(\"-virtual\", \"\"),\n",
        "        'num_class': num_classes,\n",
        "        'num_layer': num_layer,\n",
        "        'emb_dim': emb_dim,\n",
        "        'drop_ratio': drop_ratio,\n",
        "        'virtual_node': \"virtual\" in gnn_type,\n",
        "        'residual': residual,\n",
        "        'graph_pooling': pooling\n",
        "        }\n",
        "\n",
        "    model = GNN(**kwargs).to(device)\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_optimizer_and_scheduler(model, lr=lr, weight_decay=weight_decay, t_max=t_max, eta_min=eta_min):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=t_max, eta_min=eta_min)\n",
        "    return optimizer, scheduler\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7161c891",
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_small_loss(loss, forget_rate):\n",
        "    \"\"\"Select indices of samples with small losses (based on the forget rate).\"\"\"\n",
        "    if loss.ndim == 0 or len(loss) == 0:\n",
        "        return torch.tensor([], dtype=torch.long)\n",
        "    remember_rate = 1 - forget_rate\n",
        "    num_remember = max(1, int(remember_rate * len(loss)))\n",
        "    return torch.topk(-loss, k=num_remember, largest=True).indices\n",
        "\n",
        "def validate_metrics(model, val_loader, device):\n",
        "    \"\"\"Validate model performance on clean validation set using accuracy and F1 score.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            batch = batch.to(device)\n",
        "            outputs = model(batch)\n",
        "            preds = outputs.argmax(dim=1).cpu()\n",
        "            labels = batch.y.cpu()\n",
        "            \n",
        "            all_preds.append(preds)\n",
        "            all_labels.append(labels)\n",
        "    \n",
        "    all_preds = torch.cat(all_preds).numpy()\n",
        "    all_labels = torch.cat(all_labels).numpy()\n",
        "    \n",
        "    val_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    val_acc = accuracy_score(all_labels, all_preds)\n",
        "    return val_acc, val_f1\n",
        "\n",
        "def train_with_coteaching(\n",
        "    model1, model2,\n",
        "    train_dataset,\n",
        "    val_dataset,\n",
        "    criterion,\n",
        "    optimizer1, optimizer2,\n",
        "    scheduler1, scheduler2,\n",
        "    device,\n",
        "    num_epochs=100,\n",
        "    forget_rate=0.2,\n",
        "    patience=10,\n",
        "    batch_size=32\n",
        "):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    reference_model = model1\n",
        "    best_val_f1 = 0\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        model1.train()\n",
        "        model2.train()\n",
        "\n",
        "        total_loss1, total_loss2 = 0, 0\n",
        "        total_train_samples = 0\n",
        "        all_train_preds = []\n",
        "        all_train_labels = []\n",
        "        correct_train = 0\n",
        "        \n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "            batch = batch.to(device)\n",
        "            labels = batch.y\n",
        "\n",
        "            outputs1 = model1(batch)\n",
        "            outputs2 = model2(batch)\n",
        "\n",
        "            loss1 = criterion(outputs1, labels)\n",
        "            loss2 = criterion(outputs2, labels)\n",
        "\n",
        "            idx1 = select_small_loss(loss2.detach(), forget_rate)\n",
        "            idx2 = select_small_loss(loss1.detach(), forget_rate)\n",
        "            \n",
        "            if len(idx1) == 0 or len(idx2) == 0:\n",
        "                continue \n",
        "\n",
        "            final_loss1 = torch.mean(loss1[idx1])\n",
        "            final_loss2 = torch.mean(loss2[idx2])\n",
        "\n",
        "            total_loss1 += final_loss1.item() * len(idx1)\n",
        "            total_loss2 += final_loss2.item() * len(idx2)\n",
        "            total_train_samples += len(idx1)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                preds = outputs1[idx2].argmax(dim=1)\n",
        "                correct_train += (preds == labels[idx2]).sum().item()\n",
        "                all_train_preds.append(preds.cpu())\n",
        "                all_train_labels.append(labels[idx2].cpu())\n",
        "                \n",
        "            optimizer1.zero_grad()\n",
        "            final_loss1.backward()\n",
        "            optimizer1.step()\n",
        "\n",
        "            optimizer2.zero_grad()\n",
        "            final_loss2.backward()\n",
        "            optimizer2.step()\n",
        "\n",
        "        scheduler1.step()\n",
        "        scheduler2.step()\n",
        "        \n",
        "        # Compute train metrics\n",
        "        avg_train_loss = (total_loss1 + total_loss2) / (2 * total_train_samples) if total_train_samples > 0 else 0\n",
        "        train_acc = correct_train / total_train_samples if total_train_samples > 0 else 0\n",
        "        if all_train_preds and all_train_labels:\n",
        "            train_preds = torch.cat(all_train_preds).numpy()\n",
        "            train_labels = torch.cat(all_train_labels).numpy()\n",
        "            train_f1 = f1_score(train_labels, train_preds, average='macro')\n",
        "        else:\n",
        "            train_f1 = 0.0\n",
        "\n",
        "        # Validation metrics\n",
        "        val_acc, val_f1 = validate_metrics(reference_model, val_loader, device)\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}: \"\n",
        "              f\"Train Loss={avg_train_loss:.4f}, \"\n",
        "              f\"Train Acc={train_acc:.4f}, \"\n",
        "              f\"Train F1={train_f1:.4f}, \"\n",
        "              f\"Val Acc={val_acc:.4f}, \"\n",
        "              f\"Val F1={val_f1:.4f}, \"\n",
        "              f\"(Best Val F1={best_val_f1:.4f})\")\n",
        "\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_model_state = deepcopy(reference_model.state_dict())\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered!\")\n",
        "                break\n",
        "        \n",
        "    if best_model_state is not None:\n",
        "        reference_model.load_state_dict(best_model_state)\n",
        "    \n",
        "    return reference_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b7538579",
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_dataset(dataset: GraphDataset, val_ratio=0.1, seed=42):\n",
        "    labels = torch.tensor([data.y.item() for data in dataset])\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, val_idx = train_test_split(\n",
        "        indices,\n",
        "        test_size=val_ratio,\n",
        "        stratify=labels,\n",
        "        random_state=seed\n",
        "    )\n",
        "\n",
        "    train_subset = []\n",
        "    val_subset = []\n",
        "\n",
        "    for new_idx, original_idx in enumerate(train_idx):\n",
        "        data = dataset[original_idx]\n",
        "        data.idx = new_idx  # Normalize index\n",
        "        train_subset.append(data)\n",
        "\n",
        "    for new_idx, original_idx in enumerate(val_idx):\n",
        "        data = dataset[original_idx]\n",
        "        data.idx = new_idx  # Normalize index\n",
        "        val_subset.append(data)\n",
        "\n",
        "    return train_subset, val_subset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "600c2d05",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_datasets_path = [ \"datasets/B/train.json.gz\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4696ca96",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/100: 100%|██████████| 140/140 [00:08<00:00, 16.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss=1.7649, Train Acc=0.2877, Train F1=0.2096, Val Acc=0.2161, Val F1=0.1001, (Best Val F1=0.0000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/100: 100%|██████████| 140/140 [00:08<00:00, 17.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Train Loss=1.5550, Train Acc=0.2977, Train F1=0.1859, Val Acc=0.2679, Val F1=0.0936, (Best Val F1=0.1001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/100: 100%|██████████| 140/140 [00:08<00:00, 16.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Train Loss=1.5090, Train Acc=0.3314, Train F1=0.2085, Val Acc=0.3063, Val F1=0.1564, (Best Val F1=0.1001)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/100: 100%|██████████| 140/140 [00:08<00:00, 17.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: Train Loss=1.4788, Train Acc=0.3689, Train F1=0.2357, Val Acc=0.2696, Val F1=0.1946, (Best Val F1=0.1564)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/100: 100%|██████████| 140/140 [00:08<00:00, 16.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: Train Loss=1.4493, Train Acc=0.3814, Train F1=0.2384, Val Acc=0.3259, Val F1=0.1963, (Best Val F1=0.1946)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/100: 100%|██████████| 140/140 [00:08<00:00, 17.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: Train Loss=1.3723, Train Acc=0.4349, Train F1=0.3120, Val Acc=0.3375, Val F1=0.2518, (Best Val F1=0.1963)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/100: 100%|██████████| 140/140 [00:08<00:00, 17.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: Train Loss=1.3223, Train Acc=0.4657, Train F1=0.3347, Val Acc=0.3250, Val F1=0.1623, (Best Val F1=0.2518)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/100: 100%|██████████| 140/140 [00:08<00:00, 16.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: Train Loss=1.2781, Train Acc=0.4897, Train F1=0.3312, Val Acc=0.2482, Val F1=0.1560, (Best Val F1=0.2518)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/100: 100%|██████████| 140/140 [00:08<00:00, 16.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: Train Loss=1.2796, Train Acc=0.4883, Train F1=0.3369, Val Acc=0.4045, Val F1=0.2695, (Best Val F1=0.2518)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/100: 100%|██████████| 140/140 [00:08<00:00, 17.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: Train Loss=1.2489, Train Acc=0.5166, Train F1=0.3666, Val Acc=0.3571, Val F1=0.2860, (Best Val F1=0.2695)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/100: 100%|██████████| 140/140 [00:08<00:00, 17.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11: Train Loss=1.2136, Train Acc=0.5326, Train F1=0.4099, Val Acc=0.4339, Val F1=0.3197, (Best Val F1=0.2860)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/100: 100%|██████████| 140/140 [00:08<00:00, 17.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12: Train Loss=1.1936, Train Acc=0.5483, Train F1=0.4424, Val Acc=0.4196, Val F1=0.2929, (Best Val F1=0.3197)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/100: 100%|██████████| 140/140 [00:08<00:00, 17.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13: Train Loss=1.1625, Train Acc=0.5691, Train F1=0.4421, Val Acc=0.4616, Val F1=0.3520, (Best Val F1=0.3197)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/100: 100%|██████████| 140/140 [00:08<00:00, 17.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14: Train Loss=1.1579, Train Acc=0.5786, Train F1=0.4666, Val Acc=0.4393, Val F1=0.3291, (Best Val F1=0.3520)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/100: 100%|██████████| 140/140 [00:08<00:00, 16.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15: Train Loss=1.1384, Train Acc=0.5963, Train F1=0.4770, Val Acc=0.3812, Val F1=0.3154, (Best Val F1=0.3520)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/100: 100%|██████████| 140/140 [00:08<00:00, 17.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16: Train Loss=1.1219, Train Acc=0.5983, Train F1=0.4830, Val Acc=0.3839, Val F1=0.3185, (Best Val F1=0.3520)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/100: 100%|██████████| 140/140 [00:08<00:00, 16.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17: Train Loss=1.1212, Train Acc=0.6037, Train F1=0.4940, Val Acc=0.4098, Val F1=0.2916, (Best Val F1=0.3520)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/100: 100%|██████████| 140/140 [00:08<00:00, 17.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18: Train Loss=1.1071, Train Acc=0.6054, Train F1=0.4928, Val Acc=0.4580, Val F1=0.3561, (Best Val F1=0.3520)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/100: 100%|██████████| 140/140 [00:08<00:00, 16.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: Train Loss=1.0918, Train Acc=0.6163, Train F1=0.5110, Val Acc=0.4482, Val F1=0.3795, (Best Val F1=0.3561)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/100: 100%|██████████| 140/140 [00:08<00:00, 17.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20: Train Loss=1.0695, Train Acc=0.6260, Train F1=0.5250, Val Acc=0.4973, Val F1=0.4087, (Best Val F1=0.3795)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/100: 100%|██████████| 140/140 [00:08<00:00, 17.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21: Train Loss=1.0518, Train Acc=0.6351, Train F1=0.5319, Val Acc=0.4857, Val F1=0.3845, (Best Val F1=0.4087)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/100: 100%|██████████| 140/140 [00:08<00:00, 17.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22: Train Loss=1.0569, Train Acc=0.6391, Train F1=0.5416, Val Acc=0.4527, Val F1=0.3640, (Best Val F1=0.4087)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/100: 100%|██████████| 140/140 [00:08<00:00, 17.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23: Train Loss=1.0298, Train Acc=0.6497, Train F1=0.5488, Val Acc=0.4446, Val F1=0.3318, (Best Val F1=0.4087)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/100: 100%|██████████| 140/140 [00:08<00:00, 17.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24: Train Loss=1.0252, Train Acc=0.6491, Train F1=0.5558, Val Acc=0.3946, Val F1=0.3279, (Best Val F1=0.4087)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/100: 100%|██████████| 140/140 [00:08<00:00, 17.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25: Train Loss=1.0140, Train Acc=0.6520, Train F1=0.5599, Val Acc=0.4500, Val F1=0.3610, (Best Val F1=0.4087)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/100: 100%|██████████| 140/140 [00:08<00:00, 17.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26: Train Loss=1.0080, Train Acc=0.6566, Train F1=0.5646, Val Acc=0.5259, Val F1=0.4385, (Best Val F1=0.4087)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/100: 100%|██████████| 140/140 [00:08<00:00, 17.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27: Train Loss=1.0049, Train Acc=0.6557, Train F1=0.5689, Val Acc=0.5170, Val F1=0.4265, (Best Val F1=0.4385)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/100: 100%|██████████| 140/140 [00:08<00:00, 17.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28: Train Loss=0.9808, Train Acc=0.6651, Train F1=0.5779, Val Acc=0.5161, Val F1=0.4396, (Best Val F1=0.4385)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/100: 100%|██████████| 140/140 [00:08<00:00, 17.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29: Train Loss=0.9783, Train Acc=0.6657, Train F1=0.5834, Val Acc=0.4991, Val F1=0.4049, (Best Val F1=0.4396)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/100: 100%|██████████| 140/140 [00:08<00:00, 17.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30: Train Loss=0.9791, Train Acc=0.6734, Train F1=0.5875, Val Acc=0.5116, Val F1=0.4257, (Best Val F1=0.4396)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/100: 100%|██████████| 140/140 [00:08<00:00, 17.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31: Train Loss=0.9719, Train Acc=0.6680, Train F1=0.5851, Val Acc=0.4768, Val F1=0.3965, (Best Val F1=0.4396)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/100: 100%|██████████| 140/140 [00:08<00:00, 17.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32: Train Loss=0.9588, Train Acc=0.6840, Train F1=0.6113, Val Acc=0.5366, Val F1=0.4476, (Best Val F1=0.4396)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/100: 100%|██████████| 140/140 [00:08<00:00, 17.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33: Train Loss=0.9591, Train Acc=0.6866, Train F1=0.6126, Val Acc=0.5437, Val F1=0.4666, (Best Val F1=0.4476)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/100: 100%|██████████| 140/140 [00:08<00:00, 17.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34: Train Loss=0.9564, Train Acc=0.6891, Train F1=0.6147, Val Acc=0.5339, Val F1=0.4637, (Best Val F1=0.4666)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/100: 100%|██████████| 140/140 [00:08<00:00, 17.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35: Train Loss=0.9520, Train Acc=0.6923, Train F1=0.6241, Val Acc=0.5509, Val F1=0.4673, (Best Val F1=0.4666)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/100: 100%|██████████| 140/140 [00:08<00:00, 16.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36: Train Loss=0.9323, Train Acc=0.7017, Train F1=0.6264, Val Acc=0.4902, Val F1=0.4141, (Best Val F1=0.4673)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/100: 100%|██████████| 140/140 [00:08<00:00, 16.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37: Train Loss=0.9324, Train Acc=0.6986, Train F1=0.6319, Val Acc=0.5321, Val F1=0.4591, (Best Val F1=0.4673)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/100: 100%|██████████| 140/140 [00:08<00:00, 17.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38: Train Loss=0.9152, Train Acc=0.7020, Train F1=0.6341, Val Acc=0.5482, Val F1=0.4788, (Best Val F1=0.4673)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/100: 100%|██████████| 140/140 [00:08<00:00, 17.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39: Train Loss=0.9246, Train Acc=0.7114, Train F1=0.6430, Val Acc=0.5607, Val F1=0.4990, (Best Val F1=0.4788)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/100: 100%|██████████| 140/140 [00:08<00:00, 17.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40: Train Loss=0.8994, Train Acc=0.7137, Train F1=0.6517, Val Acc=0.5518, Val F1=0.4746, (Best Val F1=0.4990)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/100: 100%|██████████| 140/140 [00:08<00:00, 17.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41: Train Loss=0.9028, Train Acc=0.7083, Train F1=0.6469, Val Acc=0.5536, Val F1=0.4914, (Best Val F1=0.4990)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/100: 100%|██████████| 140/140 [00:08<00:00, 17.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42: Train Loss=0.8843, Train Acc=0.7203, Train F1=0.6579, Val Acc=0.5482, Val F1=0.4863, (Best Val F1=0.4990)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/100: 100%|██████████| 140/140 [00:08<00:00, 17.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43: Train Loss=0.8969, Train Acc=0.7123, Train F1=0.6538, Val Acc=0.5625, Val F1=0.5030, (Best Val F1=0.4990)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44/100: 100%|██████████| 140/140 [00:08<00:00, 17.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44: Train Loss=0.8836, Train Acc=0.7191, Train F1=0.6586, Val Acc=0.5598, Val F1=0.5047, (Best Val F1=0.5030)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45/100: 100%|██████████| 140/140 [00:08<00:00, 17.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45: Train Loss=0.8876, Train Acc=0.7209, Train F1=0.6608, Val Acc=0.5625, Val F1=0.5036, (Best Val F1=0.5047)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46/100: 100%|██████████| 140/140 [00:08<00:00, 17.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46: Train Loss=0.8719, Train Acc=0.7206, Train F1=0.6588, Val Acc=0.5652, Val F1=0.5104, (Best Val F1=0.5047)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47/100: 100%|██████████| 140/140 [00:08<00:00, 17.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47: Train Loss=0.8745, Train Acc=0.7174, Train F1=0.6571, Val Acc=0.5616, Val F1=0.5042, (Best Val F1=0.5104)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48/100: 100%|██████████| 140/140 [00:08<00:00, 17.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48: Train Loss=0.8888, Train Acc=0.7197, Train F1=0.6609, Val Acc=0.5616, Val F1=0.5076, (Best Val F1=0.5104)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49/100: 100%|██████████| 140/140 [00:08<00:00, 17.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49: Train Loss=0.8683, Train Acc=0.7277, Train F1=0.6689, Val Acc=0.5634, Val F1=0.5076, (Best Val F1=0.5104)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50/100: 100%|██████████| 140/140 [00:08<00:00, 17.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50: Train Loss=0.8720, Train Acc=0.7243, Train F1=0.6658, Val Acc=0.5625, Val F1=0.5043, (Best Val F1=0.5104)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 51/100: 100%|██████████| 140/140 [00:08<00:00, 17.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 51: Train Loss=0.8785, Train Acc=0.7286, Train F1=0.6713, Val Acc=0.5625, Val F1=0.5063, (Best Val F1=0.5104)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 52/100: 100%|██████████| 140/140 [00:08<00:00, 17.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 52: Train Loss=0.8786, Train Acc=0.7266, Train F1=0.6694, Val Acc=0.5643, Val F1=0.5065, (Best Val F1=0.5104)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 53/100: 100%|██████████| 140/140 [00:08<00:00, 17.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 53: Train Loss=0.8702, Train Acc=0.7229, Train F1=0.6632, Val Acc=0.5616, Val F1=0.5018, (Best Val F1=0.5104)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 54/100: 100%|██████████| 140/140 [00:08<00:00, 16.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 54: Train Loss=0.8802, Train Acc=0.7283, Train F1=0.6712, Val Acc=0.5643, Val F1=0.5059, (Best Val F1=0.5104)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 55/100: 100%|██████████| 140/140 [00:08<00:00, 17.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 55: Train Loss=0.8872, Train Acc=0.7151, Train F1=0.6551, Val Acc=0.5625, Val F1=0.5015, (Best Val F1=0.5104)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 56/100: 100%|██████████| 140/140 [00:08<00:00, 17.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 56: Train Loss=0.8834, Train Acc=0.7186, Train F1=0.6586, Val Acc=0.5607, Val F1=0.5014, (Best Val F1=0.5104)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 57/100: 100%|██████████| 140/140 [00:08<00:00, 17.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 57: Train Loss=0.8838, Train Acc=0.7214, Train F1=0.6627, Val Acc=0.5643, Val F1=0.5054, (Best Val F1=0.5104)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 58/100: 100%|██████████| 140/140 [00:08<00:00, 17.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58: Train Loss=0.8915, Train Acc=0.7123, Train F1=0.6513, Val Acc=0.5652, Val F1=0.5057, (Best Val F1=0.5104)\n",
            "Early stopping triggered!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Iterating eval graphs: 100%|██████████| 49/49 [00:03<00:00, 13.63batch/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved to /home/flaviolinux/uni/deep_learning/hackaton/submission/testset_B.csv\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "for ds in train_datasets_path:\n",
        "\n",
        "    model_kwargs = {\"gnn_type\": gnn_type, \"num_classes\":num_classes, \"num_layer\": num_layer, \"emb_dim\": emb_dim, \"drop_ratio\": drop_ratio, \"device\":device, \"residual\": residual, \"pooling\": pooling }\n",
        "    model1 = create_gnn_model(**model_kwargs)\n",
        "    model2 = create_gnn_model(**model_kwargs)\n",
        "\n",
        "    optimizer1, scheduler1 = create_optimizer_and_scheduler(model1, lr=lr, weight_decay=weight_decay)\n",
        "    optimizer2, scheduler2 = create_optimizer_and_scheduler(model2, lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    print(\"Loading dataset\")\n",
        "    full_dataset = GraphDataset(ds, transform=transforms)\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    \n",
        "    train_set, test_set = split_dataset(full_dataset, 0.2)\n",
        "    best_model = train_with_coteaching(model1=model1,\n",
        "                                       model2=model2,\n",
        "                                       train_dataset=train_set,\n",
        "                                       val_dataset=test_set,\n",
        "                                       optimizer1=optimizer1,\n",
        "                                       optimizer2=optimizer2,\n",
        "                                       scheduler1=scheduler1,\n",
        "                                       scheduler2=scheduler2,\n",
        "                                       device=device,\n",
        "                                       num_epochs=epochs,\n",
        "                                       patience = patience,\n",
        "                                       criterion=criterion)\n",
        "\n",
        "    del model1, model2, full_dataset, optimizer1, scheduler1, optimizer2, scheduler2, train_set, test_set\n",
        "    gc.collect()\n",
        "\n",
        "    test_loader = DataLoader(GraphDataset(ds.replace(\"train\", \"test\"), transform=transforms), batch_size=32)\n",
        "    predictions = evaluate(test_loader, best_model, device, False)\n",
        "    save_predictions(predictions=predictions, test_path=ds)\n",
        "\n",
        "    del test_loader, predictions \n",
        "    gc.collect()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30919,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "machine_learning_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 108.457758,
      "end_time": "2025-05-21T16:25:04.482169",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-05-21T16:23:16.024411",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
